"""
Holy-Repair Crawler
=====================
'ë°œí–‰ê¸€_ì¬ìˆ˜ì§‘í•„ìš”' í´ë”ì— ìˆëŠ” JSON íŒŒì¼ë“¤ì„ ë¡œë“œí•˜ì—¬,
ê° êµêµ¬ í™ˆí˜ì´ì§€ì—ì„œ Playwrightë¥¼ ì´ìš©í•´ ë¯¸ì‚¬ ì‹œê°„ì„ ì§ì ‘ í¬ë¡¤ë§í•©ë‹ˆë‹¤.

[ì „ëµ]
- íƒ€ê²Ÿ í•œì •: ì˜¤ì§ 'ë°œí–‰ê¸€_ì¬ìˆ˜ì§‘í•„ìš”/*.json' íŒŒì¼ë§Œ ì½ìŒ.
- ê²€ìƒ‰ ê¸°ë°˜: JSON ë‚´ church_nameìœ¼ë¡œ êµêµ¬ ì‚¬ì´íŠ¸ì—ì„œ ê²€ìƒ‰/íƒìƒ‰.
"""

import asyncio
import json
import logging
import re
import argparse
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime

from playwright.async_api import async_playwright, Page, BrowserContext

# =============================================================================
# CONFIGURATION
# =============================================================================

DIOCESE_CONFIG = {
    "êµ°ì¢…êµêµ¬": "https://www.gunjong.or.kr/main-parish/index.asp?ChurchMemberGrade=0",
    "ì•ˆë™êµêµ¬": "https://www.acatholic.or.kr/sub3/sub3.asp",
    "ëŒ€êµ¬ëŒ€êµêµ¬": "https://www.daegu-archdiocese.or.kr/page/area.html?srl=church_search",
    "ì „ì£¼êµêµ¬": "https://www.jcatholic.or.kr/theme/main/pages/area.php",
    "ì œì£¼êµêµ¬": "https://www.diocesejeju.or.kr/church_main",
    "ê´‘ì£¼ëŒ€êµêµ¬": "https://www.gjcatholic.or.kr/church/mass",
    "ì„œìš¸ëŒ€êµêµ¬": "https://aos.catholic.or.kr/pro10314",
    "ì²­ì£¼êµêµ¬": "https://www.cdcj.or.kr/parish/parish",
    "ëŒ€ì „êµêµ¬": "https://www.djcatholic.or.kr/home/pages/church.php",
    "ì¸ì²œêµêµ¬": "http://www.caincheon.or.kr",
    "ìˆ˜ì›êµêµ¬": "https://www.casuwon.or.kr/parish/parish",
    "ë¶€ì‚°êµêµ¬": "http://www.catholicbusan.or.kr/index.php?mid=page_ezLI10",
    "ì¶˜ì²œêµêµ¬": "https://www.cccatholic.or.kr/parish/missa",
    "ì›ì£¼êµêµ¬": "http://wjcatholic.or.kr/parish/time?c=ê°€ë‚˜ë‹¤ìˆœ"
}

SCRIPT_DIR = Path(__file__).parent
INPUT_DIR = SCRIPT_DIR / 'ë°œí–‰ê¸€_ì¬ìˆ˜ì§‘í•„ìš”'
OUTPUT_DIR = SCRIPT_DIR / 'ë°œí–‰ê¸€'
LOG_FILE = SCRIPT_DIR / 'holy_repair.log'

OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# =============================================================================
# LOGGING
# =============================================================================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("HolyRepair")

# =============================================================================
# UTILITY: ë¯¸ì‚¬ ì‹œê°„ íŒŒì‹± í•¨ìˆ˜
# =============================================================================

def get_chosung(text):
    """í•œê¸€ ë¬¸ìì—´ì˜ ì²« ê¸€ì ì´ˆì„±ì„ ë°˜í™˜"""
    if not text: return None
    char = text[0]
    code = ord(char) - 44032
    if code < 0 or code > 11171: return None
    
    # ì´ˆì„± ë¦¬ìŠ¤íŠ¸ (19ê°œ)
    CHOSUNG = ['ã„±', 'ã„²', 'ã„´', 'ã„·', 'ã„¸', 'ã„¹', 'ã…', 'ã…‚', 'ã…ƒ', 'ã……', 'ã…†', 'ã…‡', 'ã…ˆ', 'ã…‰', 'ã…Š', 'ã…‹', 'ã…Œ', 'ã…', 'ã…']
    return CHOSUNG[code // 588]

def normalize_time(time_str, ampm):
    if not ampm: return time_str 
    try:
        hour, minute = map(int, time_str.split(':'))
        if ampm == "ì˜¤í›„" and hour < 12:
            hour += 12
        elif ampm == "ì˜¤ì „" and hour == 12:
            hour = 0
        return f"{hour:02d}:{minute:02d}"
    except:
        return time_str

def expand_days(day_expression):
    weekdays = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼", "ì£¼ì¼"]
    if "ë§¤ì¼" in day_expression:
        return ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì£¼ì¼"]
    if '-' in day_expression:
        try:
            start, end = day_expression.split('-')
            if start == "ì¼": start = "ì£¼ì¼"
            if end == "ì¼": end = "ì£¼ì¼"
            s_idx = weekdays.index(start)
            e_idx = weekdays.index(end)
            return weekdays[s_idx:e_idx+1]
        except:
            return [day_expression] 
    return [day_expression]

def _parse_daegu_style(text: str) -> Dict[str, Any]:
    """ëŒ€êµ¬ëŒ€êµêµ¬ ìŠ¤íƒ€ì¼ íŒŒì‹± (ì„¹ì…˜, ì˜¤ì „/ì˜¤í›„, ìš”ì¼ë²”ìœ„ ì§€ì›)"""
    result = {
        "ì£¼ì¼ë¯¸ì‚¬": [],
        "í‰ì¼ë¯¸ì‚¬": [],
        "í† ìš”ë¯¸ì‚¬": [],
        "ê¸°íƒ€": [],
        "raw_text": text[:500]
    }
    
    current_section = "ê¸°íƒ€"
    
    # í…ìŠ¤íŠ¸ ì •ê·œí™”: ì¤„ë°”ê¿ˆ ì‚½ì…
    # [ì£¼ì¼ë¯¸ì‚¬], [í‰ì¼ë¯¸ì‚¬] ì•ì— ì¤„ë°”ê¿ˆ
    normalized = text
    normalized = re.sub(r'\[ì£¼ì¼ë¯¸ì‚¬\]', r'\n[ì£¼ì¼ë¯¸ì‚¬]\n', normalized)
    normalized = re.sub(r'\[í‰ì¼ë¯¸ì‚¬\]', r'\n[í‰ì¼ë¯¸ì‚¬]\n', normalized)
    # "í† ìš”ì¼ -", "ì£¼ì¼ -" ì•ì— ì¤„ë°”ê¿ˆ
    normalized = re.sub(r'(í† ìš”ì¼\s*-)', r'\n\1', normalized)
    normalized = re.sub(r'(ì£¼ì¼\s*-)', r'\n\1', normalized)
    # "ì˜¤ì „", "ì˜¤í›„" ì•ì— ì¤„ë°”ê¿ˆ (ë‹¨, ì‹œê°„ ë’¤ì— ì˜¤ëŠ” ê²ƒì€ ì œì™¸ - ì–´ë ¤ì›€)
    # ì¼ë‹¨ skip
    
    lines = normalized.split('\n')
    for line in lines:
        line = line.strip()
        if not line: continue
        
        if "[ì£¼ì¼ë¯¸ì‚¬]" in line:
            current_section = "ì£¼ì¼ë¯¸ì‚¬"
            continue
        if "[í‰ì¼ë¯¸ì‚¬]" in line:
            current_section = "í‰ì¼ë¯¸ì‚¬"
            continue
            
        current_ampm = None 
        current_days = []
        
        token_pattern = re.compile(r'(ì˜¤ì „|ì˜¤í›„)|([ì›”í™”ìˆ˜ëª©ê¸ˆí† ì¼ì£¼ì¼]-[ì›”í™”ìˆ˜ëª©ê¸ˆí† ì¼ì£¼ì¼])|([ì›”í™”ìˆ˜ëª©ê¸ˆí† ì¼ì£¼ì¼](?!ìš”|ì€|ëŠ”))|(\d{1,2}:\d{2})|(\([^)]+\))')
        
        clean_line = line.replace("í† ìš”ì¼", "í† ").replace("ì¼ìš”ì¼", "ì£¼ì¼")
        matches = token_pattern.finditer(clean_line)
        
        last_added_entries = []
        
        for match in matches:
            ampm, day_range, day, time_str, desc = match.groups()
            
            if ampm:
                current_ampm = ampm
            elif day_range:
                current_days = expand_days(day_range)
            elif day:
                current_days = [day]
            elif time_str:
                final_time = normalize_time(time_str, current_ampm)
                days_to_apply = current_days
                if not days_to_apply:
                    if current_section == "ì£¼ì¼ë¯¸ì‚¬": days_to_apply = ["ì£¼ì¼"]
                    elif current_section == "í† ìš”ë¯¸ì‚¬": pass
                
                new_entries = []
                for d in days_to_apply:
                    category = current_section
                    if d == "í† " and current_section == "ì£¼ì¼ë¯¸ì‚¬":
                        category = "í† ìš”ë¯¸ì‚¬"
                    if category == "í‰ì¼ë¯¸ì‚¬" and d == "ì£¼ì¼":
                         category = "ì£¼ì¼ë¯¸ì‚¬"

                    entry = {"ì‹œê°„": final_time, "ì„¤ëª…": "", "ìš”ì¼": d}
                    result[category].append(entry)
                    new_entries.append(entry)
                last_added_entries = new_entries
                
            elif desc:
                clean_desc = desc.strip('()')
                if last_added_entries:
                    for entry in last_added_entries:
                        if entry["ì„¤ëª…"]: entry["ì„¤ëª…"] += " " + clean_desc
                        else: entry["ì„¤ëª…"] = clean_desc

    # ê²°ê³¼ ì •ë¦¬
    final_result = {"raw_text": text[:500]}
    
    # í•„í„°ë§í•  í‚¤ì›Œë“œ (íŠ¹ìˆ˜ ë¯¸ì‚¬, êµë¦¬ ë“±)
    filter_keywords = ["í›„ì›íšŒ", "êµë¦¬", "êµì •ì‚¬ëª©"]
    
    for cat, entries in result.items():
        if cat == "raw_text": continue
        seen = set()
        clean_entries = []
        for e in entries:
            # í•„í„°ë§: íŠ¹ìˆ˜ í‚¤ì›Œë“œ í¬í•¨ ì‹œ ìŠ¤í‚µ
            if any(kw in e['ì„¤ëª…'] for kw in filter_keywords):
                continue
                
            if cat == "í‰ì¼ë¯¸ì‚¬":
                if e['ìš”ì¼'] not in e['ì„¤ëª…']:
                     e['ì„¤ëª…'] = f"{e['ìš”ì¼']} {e['ì„¤ëª…']}".strip()
            
            key = f"{e['ì‹œê°„']}|{e['ì„¤ëª…']}"
            if key not in seen:
                seen.add(key)
                if 'ìš”ì¼' in e: del e['ìš”ì¼']
                clean_entries.append(e)
        
        if clean_entries:
            final_result[cat] = clean_entries

    return final_result

def parse_mass_times_from_text(text: str) -> Dict[str, Any]:
    """
    í…ìŠ¤íŠ¸ì—ì„œ ë¯¸ì‚¬ ì‹œê°„ ì •ë³´ë¥¼ ì¶”ì¶œ.
    ì§€ì› íŒ¨í„´:
    1. ëŒ€êµ¬í˜• (ì„¹ì…˜, ì˜¤ì „/ì˜¤í›„, ë²”ìœ„)
    2. ì„œìš¸í˜•/ìˆ˜ì›í˜• (HH:MM)
    """
    # ëŒ€êµ¬í˜• íŒ¨í„´ ì²´í¬
    if "[ì£¼ì¼ë¯¸ì‚¬]" in text or "[í‰ì¼ë¯¸ì‚¬]" in text:
        return _parse_daegu_style(text)
        
    # ê¸°ì¡´ ë¡œì§ (ì„œìš¸/ìˆ˜ì›)
    result = {
        "ì£¼ì¼ë¯¸ì‚¬": [],
        "í‰ì¼ë¯¸ì‚¬": [],
        "í† ìš”ë¯¸ì‚¬": [],
        "ê¸°íƒ€": [],
        "raw_text": text[:500]
    }
    
    # íŒ¨í„´ 1: ì‹œê°„ + (ì„¤ëª…)
    pattern1 = r'(\d{1,2}:\d{2})\s*\(([^)]+)\)'
    matches1 = re.findall(pattern1, text)
    
    for time_str, desc in matches1:
        entry = {"ì‹œê°„": time_str, "ì„¤ëª…": desc}
        _classify_mass(result, entry, desc)
            
    # íŒ¨í„´ 2: ìš”ì¼ + ì‹œê°„ë“¤ (ìˆ˜ì›í˜•)
    days = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì£¼ì¼", "ì¼"]
    lines = text.split('\n')
    for line in lines:
        line = line.strip()
        if not line: continue
        
        if any(line.startswith(d) for d in days) or any(line.startswith(f"{d}ìš”ì¼") for d in days):
            # ëŒ€êµ¬í˜•ì¸ì§€ í•œë²ˆ ë” ì²´í¬? ì•„ë‹ˆì˜¤, ìœ„ì—ì„œ ê±¸ë €ìŒ.
            times = re.findall(r'(\d{1,2}:\d{2})', line)
            if times:
                # ìš”ì¼ ì°¾ê¸°
                day_found = ""
                for d in days:
                    if line.startswith(d):
                        day_found = d
                        break
                
                for t in times:
                    desc = f"{day_found}ìš”ì¼ {t} ë¯¸ì‚¬"
                    entry = {"ì‹œê°„": t, "ì„¤ëª…": desc}
                    _classify_mass(result, entry, day_found)

    # ì¤‘ë³µ ì œê±°
    for cat in result:
        if isinstance(result[cat], list):
            unique = []
            seen = set()
            for item in result[cat]:
                key = f"{item['ì‹œê°„']}|{item['ì„¤ëª…']}"
                if key not in seen:
                    seen.add(key)
                    unique.append(item)
            result[cat] = unique

    result = {k: v for k, v in result.items() if v}
    return result if len(result) > 1 else None

def _classify_mass(result_dict, entry, keyword_source):
    """ë¯¸ì‚¬ ë¶„ë¥˜ í—¬í¼"""
    k = keyword_source.lower()
    if any(w in k for w in ["ì£¼ì¼", "ì¼ìš”ì¼", "êµì¤‘", "ì²­ë…„", "ì²­ì†Œë…„"]):
        result_dict["ì£¼ì¼ë¯¸ì‚¬"].append(entry)
    elif any(w in k for w in ["í† ìš”", "í† ", "íŠ¹ì „"]):
        result_dict["í† ìš”ë¯¸ì‚¬"].append(entry)
    elif any(w in k for w in ["í‰ì¼", "ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ"]):
        result_dict["í‰ì¼ë¯¸ì‚¬"].append(entry)
    else:
        result_dict["ê¸°íƒ€"].append(entry)

# =============================================================================
# CRAWLER CLASS
# =============================================================================

class RepairCrawler:
    def __init__(self, headless: bool = False):
        self.headless = headless
        self.browser = None
        self.context: BrowserContext = None
        self.playwright = None
        self.stats = {"total": 0, "success": 0, "failed": 0}

    async def start(self):
        """Playwright ì‹œì‘"""
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(headless=self.headless)
        self.context = await self.browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        )
        logger.info("ğŸš€ Holy-Repair Crawler Started")

    async def stop(self):
        """Playwright ì¢…ë£Œ"""
        if self.context: await self.context.close()
        if self.browser: await self.browser.close()
        if self.playwright: await self.playwright.stop()
        logger.info(f"ğŸ‘‹ Holy-Repair Crawler Stopped | Stats: {self.stats}")

    # =========================================================================
    # íŒŒì¼ ì²˜ë¦¬ (Targeted Repair - í•µì‹¬ ë¡œì§ ê²€ì¦ë¨)
    # =========================================================================
    
    async def process_files(self, limit: int = None):
        """
        [í•µì‹¬] ì˜¤ì§ 'ë°œí–‰ê¸€_ì¬ìˆ˜ì§‘í•„ìš”' í´ë”ì˜ JSONë§Œ ì½ì–´ì„œ ì²˜ë¦¬.
        ì „ì²´ ì„±ë‹¹ì„ ê¸ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, JSONì— ëª…ì‹œëœ ì„±ë‹¹ë§Œ íƒ€ê²ŸíŒ….
        """
        # failed_ íŒŒì¼ ìš°ì„  ì²˜ë¦¬ (ì´ì „ì— ì‹¤íŒ¨í•œ ê²ƒë“¤)
        files = list(INPUT_DIR.glob('failed_posts_batch_*.json'))
        files += list(INPUT_DIR.glob('posts_batch_*.json'))
        
        if not files:
            logger.warning(f"âš ï¸ No files found in {INPUT_DIR}")
            return
            
        logger.info(f"ğŸ“‚ Found {len(files)} target files in 'ë°œí–‰ê¸€_ì¬ìˆ˜ì§‘í•„ìš”'")

        for file_path in files:
            await self.process_single_file(file_path, limit=limit)

    async def process_single_file(self, file_path: Path, limit: int = None):
        logger.info(f"ğŸ“„ Processing: {file_path.name}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                posts = json.load(f)
        except Exception as e:
            logger.error(f"Failed to load {file_path}: {e}")
            return

        repaired_posts = []
        failed_posts = []
        
        posts_to_process = posts[:limit] if limit else posts
        
        for idx, post in enumerate(posts_to_process):
            # church_nameì—ì„œ "ì„±ë‹¹" ì œê±°
            church_name = post.get('church_name', '').replace("ì„±ë‹¹", "").strip()
            
            # êµêµ¬ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì£¼ì†Œì—ì„œ ì¶”ë¡ 
            diocese = post.get('diocese', '')
            if not diocese:
                address = post.get('address', '')
                diocese = self.infer_diocese(address)
            
            if not church_name or not diocese:
                # logger.debug(f"Skipping invalid entry: {church_name} (Addr: {post.get('address')})")
                continue
            
            # êµêµ¬ë³„ í•¸ë“¤ëŸ¬ ì„ íƒ
            handler = self.get_handler(diocese)
            if not handler:
                # logger.debug(f"No handler for: {diocese}")
                failed_posts.append(post)
                continue

            self.stats["total"] += 1
            logger.info(f"[{idx+1}/{len(posts_to_process)}] ğŸ” {diocese} - {church_name}")
            
            try:
                page = await self.context.new_page()
                result_data = await handler(page, church_name, post)
                await page.close()
                
                if result_data and len(result_data) > 1:  # ìœ íš¨í•œ ë°ì´í„°
                    logger.info(f"  âœ… SUCCESS: {church_name}")
                    post['repaired_mass_times'] = result_data
                    post['repair_source'] = 'holy_repair_crawler'
                    post['repair_timestamp'] = datetime.now().isoformat()
                    repaired_posts.append(post)
                    self.stats["success"] += 1
                else:
                    logger.info(f"  âŒ FAILED: {church_name}")
                    failed_posts.append(post)
                    self.stats["failed"] += 1
                    
            except Exception as e:
                logger.error(f"  âŒ ERROR: {church_name} - {e}")
                failed_posts.append(post)
                self.stats["failed"] += 1
        
        # ê²°ê³¼ ì €ì¥
        if repaired_posts:
            out_path = OUTPUT_DIR / f"repaired_{file_path.name}"
            with open(out_path, 'w', encoding='utf-8') as f:
                json.dump(repaired_posts, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ’¾ Saved {len(repaired_posts)} repaired items -> {out_path.name}")

    def infer_diocese(self, address: str) -> str:
        """ì£¼ì†Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµêµ¬ë¥¼ ì¶”ë¡ """
        if not address: return ""
        
        if "ì„œìš¸" in address: return "ì„œìš¸ëŒ€êµêµ¬"
        if "ëŒ€êµ¬" in address: return "ëŒ€êµ¬ëŒ€êµêµ¬"
        if "ê´‘ì£¼" in address: return "ê´‘ì£¼ëŒ€êµêµ¬"
        if "ì œì£¼" in address: return "ì œì£¼êµêµ¬"
        if "ëŒ€ì „" in address or "ì„¸ì¢…" in address or "ì¶©ë‚¨" in address or "ì¶©ì²­ë‚¨ë„" in address: return "ëŒ€ì „êµêµ¬"
        if "ë¶€ì‚°" in address: return "ë¶€ì‚°êµêµ¬"
        if "ì¸ì²œ" in address: return "ì¸ì²œêµêµ¬" # ë¶€ì²œ/ê¹€í¬ ë“±ì€ ë³„ë„ ë¡œì§ í•„ìš”í•  ìˆ˜ ìˆìŒ
        if "ì „ë¶" in address or "ì „ë¼ë¶ë„" in address: return "ì „ì£¼êµêµ¬"
        if "ì¶©ë¶" in address or "ì¶©ì²­ë¶ë„" in address: return "ì²­ì£¼êµêµ¬"
        if "ê°•ì›" in address or "ê°•ì›ë„" in address:
            # ì¶˜ì²œ/ì›ì£¼ êµ¬ë¶„ ì–´ë µì§€ë§Œ ì¼ë‹¨ ì¶˜ì²œìœ¼ë¡œ ë§¤í•‘í•˜ê±°ë‚˜ ë‘˜ ë‹¤ ì‹œë„?
            # ì›ì£¼ì‹œê°€ í¬í•¨ë˜ë©´ ì›ì£¼êµêµ¬
            if "ì›ì£¼" in address: return "ì›ì£¼êµêµ¬"
            return "ì¶˜ì²œêµêµ¬"
            
        # ê²½ê¸° ì§€ì—­ì€ ë³µì¡í•¨ (ìˆ˜ì›/ì¸ì²œ/ì˜ì •ë¶€)
        if "ê²½ê¸°" in address:
            if any(c in address for c in ["ìˆ˜ì›", "ì„±ë‚¨", "ìš©ì¸", "ì•ˆì–‘", "ì•ˆì‚°", "í™”ì„±", "í‰íƒ"]): return "ìˆ˜ì›êµêµ¬"
            if any(c in address for c in ["ê³ ì–‘", "ì˜ì •ë¶€", "íŒŒì£¼", "ë‚¨ì–‘ì£¼", "êµ¬ë¦¬"]): return "ì˜ì •ë¶€êµêµ¬" # ì„¤ì •ì— ì—†ìœ¼ë©´ ë¬´ì‹œë¨
            if any(c in address for c in ["ë¶€ì²œ", "ê¹€í¬"]): return "ì¸ì²œêµêµ¬"
            return "ìˆ˜ì›êµêµ¬" # ê¸°ë³¸ê°’

        return ""

    def get_handler(self, diocese: str):
        """êµêµ¬ëª… -> í•¸ë“¤ëŸ¬ í•¨ìˆ˜ ë§¤í•‘"""
        normalized = diocese.replace("ì²œì£¼êµ", "").replace(" ", "").strip()
        
        if "ì„œìš¸" in normalized: return self.handle_seoul
        if "ëŒ€êµ¬" in normalized: return self.handle_daegu
        if "ìˆ˜ì›" in normalized: return self.handle_suwon
        if "ì¸ì²œ" in normalized: return self.handle_incheon
        if "ë¶€ì‚°" in normalized: return self.handle_busan
        
        return None

    # =========================================================================
    # HANDLERS (êµêµ¬ë³„ ìƒì„¸ êµ¬í˜„)
    # =========================================================================

    async def handle_seoul(self, page: Page, church_name: str, post: dict) -> Optional[Dict]:
        """
        ì„œìš¸ëŒ€êµêµ¬ í•¸ë“¤ëŸ¬
        
        [í˜ì´ì§€ êµ¬ì¡° ë¶„ì„ ê²°ê³¼ - ì—…ë°ì´íŠ¸ë¨]
        - URL: https://aos.catholic.or.kr/pro10314
        - ê²€ìƒ‰ì°½: input#srchText (class="inp")
        - ê²€ìƒ‰ ë²„íŠ¼: ì—”í„°í‚¤ ë˜ëŠ” ë²„íŠ¼ í´ë¦­
        - ê²°ê³¼: í•´ë‹¹ ì„±ë‹¹ì˜ ë¯¸ì‚¬ ì‹œê°„ì´ ë¦¬ìŠ¤íŠ¸ë¡œ í‘œì‹œ
        """
        base_url = DIOCESE_CONFIG["ì„œìš¸ëŒ€êµêµ¬"]
        
        try:
            logger.info(f"  ğŸŒ Opening Seoul diocese page...")
            await page.goto(base_url, timeout=15000)
            await page.wait_for_load_state("networkidle")
            
            # ê²€ìƒ‰ì°½ ì°¾ê¸°
            search_input = page.locator("#srchText")
            if await search_input.count() == 0:
                search_input = page.locator("input.inp")
            
            if await search_input.count() == 0:
                logger.warning("  âš ï¸ Search input not found!")
                return None
            
            logger.info(f"  ğŸ” Searching for '{church_name}'...")
            await search_input.first.fill(church_name)
            await page.keyboard.press("Enter")
            
            # ê²°ê³¼ ë¡œë”© ëŒ€ê¸°
            await page.wait_for_load_state("networkidle")
            await asyncio.sleep(1)  # ì¶”ê°€ ëŒ€ê¸° (ë™ì  ì½˜í…ì¸ )
            
            # ê²°ê³¼ í˜ì´ì§€ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            text_content = await page.inner_text("body")
            logger.info(f"  ğŸ“ Result text length: {len(text_content)} chars")
            
            # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì„±ë‹¹ëª… í™•ì¸
            if church_name not in text_content and "ê²€ìƒ‰ê²°ê³¼" not in text_content:
                # í˜¹ì‹œ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ í‘œì‹œë˜ëŠ”ì§€ ì²´í¬
                logger.info(f"  âš ï¸ '{church_name}' ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ. í˜ì´ì§€ ë‚´ìš© ìƒ˜í”Œ:")
                logger.info(f"  {text_content[:300]}...")
                return None
            
            logger.info(f"  âœ… Found results for '{church_name}'")
            
            # ë¯¸ì‚¬ ì‹œê°„ ì¶”ì¶œ
            # íŒ¨í„´: "HH:MM (ì„¤ëª…)" 
            result = parse_mass_times_from_text(text_content)
            
            if result:
                result["search_term"] = church_name
                return result
            
            # Fallback: ì „ì²´ í…ìŠ¤íŠ¸ë¼ë„ ì €ì¥
            return {
                "raw_text": text_content[:1000],
                "search_term": church_name,
                "parsing_failed": True
            }
            
        except Exception as e:
            logger.error(f"  âŒ Seoul handler error: {e}")
            return None

    async def handle_suwon(self, page: Page, church_name: str, post: dict) -> Optional[Dict]:
        """ìˆ˜ì›êµêµ¬ í•¸ë“¤ëŸ¬"""
        url = DIOCESE_CONFIG["ìˆ˜ì›êµêµ¬"]
        
        try:
            logger.info(f"  ğŸŒ Opening Suwon diocese page...")
            await page.goto(url, timeout=20000)
            await page.wait_for_load_state("domcontentloaded")
            
            # ê²€ìƒ‰ì°½ ì°¾ê¸° (ì¢€ ë” ìœ ì—°í•˜ê²Œ)
            search_input = page.locator("input[name='k']")
            if await search_input.count() == 0:
                search_input = page.locator("input#k")
            
            # ê²€ìƒ‰ì°½ì´ ì•ˆ ë³´ì¼ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ìŠ¤í¬ë¡¤
            await page.evaluate("window.scrollTo(0, 0)")
            
            if await search_input.count() > 0:
                logger.info(f"  ğŸ” Searching for '{church_name}'...")
                await search_input.first.fill(church_name)
                
                # ì—”í„°í‚¤ ì´ë²¤íŠ¸ ë˜ëŠ” ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­
                # ê²€ìƒ‰ ë²„íŠ¼: .btn_search ë˜ëŠ” form submit
                if await page.locator("button.btn_search").count() > 0:
                    await page.locator("button.btn_search").click()
                elif await page.locator("input[type='submit']").count() > 0:
                     await page.locator("input[type='submit']").click()
                else:
                    await page.keyboard.press("Enter")
                
                await page.wait_for_load_state("networkidle")
                
                # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ í™•ì¸
                logger.info("  ğŸ‘€ Checking results...")
                
                # ê²°ê³¼ í…Œì´ë¸” ì¡´ì¬ í™•ì¸
                if await page.locator("table").count() == 0:
                    logger.warning("  âš ï¸ Result table not found.")
                    return None
                
                # ëª…ì‹œì ìœ¼ë¡œ ë§í¬ ëŒ€ê¸° (3ì´ˆ)
                try:
                    await page.wait_for_selector("table tbody tr a", timeout=3000)
                except:
                    pass
                
                # ëª¨ë“  trì„ ìˆœíšŒí•˜ë©° ì°¾ê¸°
                rows = await page.locator("table tbody tr").all()
                logger.info(f"  Found {len(rows)} rows in result table.")
                
                for row in rows:
                    text = await row.inner_text()
                    if church_name in text:
                        logger.info(f"  âœ… Found '{church_name}' in row. Clicking...")
                        link = row.locator("a")
                        if await link.count() > 0:
                            # ìƒˆ íƒ­ìœ¼ë¡œ ì—´ë¦´ ìˆ˜ë„ ìˆìœ¼ë‹ˆ context ê°ì‹œ? 
                            # ë³´í†µì€ ê°™ì€ ì°½ ì´ë™
                            await link.first.click()
                            await page.wait_for_load_state("domcontentloaded")
                            await asyncio.sleep(1) 
                            
                            # ìƒì„¸ í˜ì´ì§€ íŒŒì‹±
                            content = await page.inner_text("body")
                            logger.info(f"  ğŸ“ Content excerpt: {content[:500].replace(chr(10), ' ')}") # ë””ë²„ê¹…ìš©
                            
                            result = parse_mass_times_from_text(content)
                            if result:
                                result["search_term"] = church_name
                                return result
                        else:
                            logger.warning("  âš ï¸ Found row but no link anchor.")
            else:
                logger.error("  âŒ Search input not found. Dump inputs:")
                inputs = await page.locator("input").all()
                for inp in inputs:
                    name = await inp.get_attribute("name")
                    logger.info(f"    - input name={name}")
            
        except Exception as e:
            logger.error(f"  âŒ Suwon handler error: {e}")
            
        return None

    async def handle_daegu(self, page: Page, church_name: str, post: dict) -> Optional[Dict]:
        """ëŒ€êµ¬ëŒ€êµêµ¬ í•¸ë“¤ëŸ¬"""
        url = DIOCESE_CONFIG["ëŒ€êµ¬ëŒ€êµêµ¬"]
        
        try:
            logger.info(f"  ğŸŒ Opening Daegu diocese page...")
            await page.goto(url, timeout=15000)
            await page.wait_for_load_state("domcontentloaded")
            
            # ê²€ìƒ‰ì°½ ì°¾ê¸°: id='search', name='search', class='church_search_input'
            search_input = page.locator("input#search")
            if await search_input.count() == 0:
                search_input = page.locator("input.church_search_input")
            if await search_input.count() == 0:
                search_input = page.locator("input[name='search']")
                
            if await search_input.count() > 0:
                # ëŒ€êµ¬êµêµ¬ ê²€ìƒ‰ì–´ íŠœë‹: "ì£¼êµì¢Œ" ì œê±° (ì˜ˆ: ê³„ì‚°ì£¼êµì¢Œ -> ê³„ì‚°)
                search_term = church_name.replace("ì£¼êµì¢Œ", "").strip()
                logger.info(f"  ğŸ” Searching for '{search_term}' (Original: {church_name})...")
                
                await search_input.first.fill(search_term)
                
                # ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­ (ì—”í„°ê°€ ì•ˆ ë¨¹í ìˆ˜ë„ ìˆì–´ì„œ ë²„íŠ¼ í´ë¦­ ì‹œë„)
                # ëŒ€êµ¬êµêµ¬ ë²„íŠ¼: input.btn_search ë˜ëŠ” img.btn_search ë“±
                # ì¼ë‹¨ ì—”í„° ë¨¼ì €
                await page.keyboard.press("Enter")
                await page.wait_for_load_state("networkidle")
                await asyncio.sleep(2) # ê²°ê³¼ ë¡œë”© ëŒ€ê¸°
                
                # ê²°ê³¼ íŒŒì‹±
                logger.info("  ğŸ‘€ Checking results...")
                
                # ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë‚˜ì˜´. í´ë¦­í•´ì•¼ í•¨.
                # "ê²€ìƒ‰ê²°ê³¼ : ì „ì²´ Nê±´" í™•ì¸ - ì—†ìœ¼ë©´ ì‹¤íŒ¨
                content = await page.inner_text("body")
                if "ê²€ìƒ‰ê²°ê³¼ : ì „ì²´ 0ê±´" in content:
                    logger.warning(f"  âš ï¸ No results found for '{search_term}'")
                    return None

                # ì²« ë²ˆì§¸ ê²°ê³¼ í´ë¦­ (class="result_tit" ë˜ëŠ” table ë‚´ ë§í¬)
                # ëŒ€êµ¬êµêµ¬ êµ¬ì¡° ì¶”ì •: ê²Œì‹œíŒ í˜•íƒœ ë¦¬ìŠ¤íŠ¸
                # ë§í¬ ì°¾ê¸°: search_termì„ í¬í•¨í•˜ëŠ” a íƒœê·¸
                
                # ì¢€ ë” ëª…ì‹œì ì¸ ë§í¬ë¥¼ ì°¾ê¸° ìœ„í•´ wait
                try:
                    # ì„±ë‹¹ëª…(íŠœë‹ëœ)ì´ í¬í•¨ëœ ë§í¬ ëŒ€ê¸°
                    await page.wait_for_selector(f"a:has-text('{search_term}')", timeout=3000)
                except:
                    pass

                # ë§í¬ í´ë¦­ ì‹œë„
                links = await page.locator("a").all()
                found_link = False
                
                for link in links:
                    txt = await link.inner_text()
                    if search_term in txt and len(txt) < 20: # ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ ì œì™¸
                        logger.info(f"  âœ… Found link '{txt}'. Clicking...")
                        try:
                            await link.click()
                            await page.wait_for_load_state("domcontentloaded")
                            await asyncio.sleep(1)
                            found_link = True
                            break
                        except Exception as e:
                            logger.warning(f"  âš ï¸ Failed to click link: {e}")
                
                if not found_link:
                    logger.warning("  âš ï¸ Found results but could not locate click target.")
                    return None
                    
                # ìƒì„¸ í˜ì´ì§€ íŒŒì‹±
                content = await page.inner_text("body")
                logger.info(f"  ğŸ“ Content excerpt: {content[:1500].replace(chr(10), ' ')}")
                
                result = parse_mass_times_from_text(content)
                if result:
                    result["search_term"] = search_term
                    return result
                else:
                    logger.warning("  âš ï¸ Parsed result is empty. Detailed parsing might be needed.")
            else:
                logger.error("  âŒ Search input not found.")
                # ë””ë²„ê·¸: ì¸í’‹ ë‹¤ ì¶œë ¥
                inputs = await page.locator("input").all()
                for inp in inputs:
                    logger.info(f"    - input: {await inp.evaluate('el => el.outerHTML')}")

        except Exception as e:
            logger.error(f"  âŒ Daegu handler error: {e}")
            
        return None

    async def handle_incheon(self, page: Page, church_name: str, post: dict) -> Optional[Dict]:
        """
        ì¸ì²œêµêµ¬ í•¸ë“¤ëŸ¬
        
        [í˜ì´ì§€ êµ¬ì¡°]
        - ëª©ë¡: http://www.caincheon.or.kr/church/church_misa.do
        - ìƒì„¸: http://www.caincheon.or.kr/church/church_jigu.do?churchIdx=...
        - ê²€ìƒ‰ì°½ì´ ì—†ê³ , ëª©ë¡ì—ì„œ í´ë¦­í•´ì„œ ë“¤ì–´ê°€ì•¼ í•¨.
        - ë¯¸ì‚¬ì‹œê°„ í‘œê¸°: í…ìŠ¤íŠ¸ ("ì›” ì˜¤ì „ 6ì‹œ 30ë¶„")
        """
        list_url = DIOCESE_CONFIG["ì¸ì²œêµêµ¬"] + "/church/church_misa.do" # config url ë³´ì • í•„ìš”í•  ìˆ˜ë„
        if not list_url.startswith("http"): # DIOCESE_CONFIG["ì¸ì²œêµêµ¬"]ê°€ base urlì¼ ê²½ìš°
             list_url = "http://www.caincheon.or.kr/church/church_misa.do"

        try:
            logger.info(f"  ğŸŒ Opening Incheon diocese list page...")
            await page.goto(list_url, timeout=20000)
            await page.wait_for_load_state("domcontentloaded")
            
            # ì„±ë‹¹ëª…ìœ¼ë¡œ ë§í¬ ì°¾ê¸°
            # ì¸ì²œêµêµ¬ ëª©ë¡ì—ëŠ” "ê°€ì •3ë™", "ê°€ì •ë™" ì²˜ëŸ¼ "ì„±ë‹¹"ì´ ë¹ ì§„ ì´ë¦„ìœ¼ë¡œ ë˜ì–´ ìˆìŒ.
            # ì…ë ¥ëœ church_nameì—ì„œ "ì„±ë‹¹"ì„ ëº€ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰
            target_name = church_name.replace("ì„±ë‹¹", "").strip()
            
            logger.info(f"  ğŸ” Finding link for '{target_name}'...")
            
            # ëª¨ë“  ë§í¬ í…ìŠ¤íŠ¸ í™•ì¸
            found_link = None
            links = await page.locator(".con_area a").all() # .con_area ë‚´ì˜ ë§í¬ë¡œ í•œì •
            
            if not links:
                 links = await page.locator("a").all() # ì‹¤íŒ¨ì‹œ ì „ì²´ ê²€ìƒ‰

            for link in links:
                txt = await link.inner_text()
                txt = txt.strip()
                if txt == target_name: # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê²ƒ ìš°ì„ 
                    found_link = link
                    break
            
            if not found_link:
                # í¬í•¨ë˜ëŠ” ê²ƒ ì¬ê²€ìƒ‰ (ì˜ˆ: "ê°€ì •3ë™" -> "ê°€ì •3ë™(ì¤€)" ê°™ì€ ì¼€ì´ìŠ¤ ëŒ€ë¹„)
                for link in links:
                    txt = await link.inner_text()
                    txt = txt.strip()
                    if target_name in txt and len(txt) < len(target_name) + 5:
                        found_link = link
                        break
            
            if found_link:
                logger.info(f"  âœ… Found link: {await found_link.inner_text()} -> Clicking...")
                await found_link.click()
                
                # ìƒì„¸ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
                try:
                    # "ë¯¸ì‚¬ì•ˆë‚´" ë˜ëŠ” "ì„±ë‹¹ì •ë³´" ê°€ ë‚˜ì˜¬ ë•Œê¹Œì§€ ëŒ€ê¸°
                    await page.wait_for_load_state("networkidle")
                    # h4 íƒœê·¸ ë“±ì„ ê¸°ë‹¤ë¦¼
                    await asyncio.sleep(2) 
                except:
                    pass
                
                # ìƒì„¸ í˜ì´ì§€ íŒŒì‹±
                body_text = await page.inner_text("body")
                # print(f"DEBUG_BODY_LEN: {len(body_text)}") # ë””ë²„ê¹…
                
                # "ë¯¸ì‚¬ì•ˆë‚´" í…ìŠ¤íŠ¸ í™•ì¸
                if "ë¯¸ì‚¬ì•ˆë‚´" in body_text:
                    # ë¯¸ì‚¬ì•ˆë‚´ ì„¹ì…˜ ì¶”ì¶œ
                    split_text = body_text.split("ë¯¸ì‚¬ì•ˆë‚´")
                    if len(split_text) > 1:
                        target_text = split_text[1]
                        
                        # "ë¹„ê³ " ë˜ëŠ” ë‹¤ìŒ ì„¹ì…˜ ì „ê¹Œì§€
                        for terminator in ["ë¹„ê³ ", "ë³¸ë‹¹ ì†Œì‹", "ìˆ˜ë„íšŒ", "ê´€í• êµ¬ì—­"]:
                            if terminator in target_text:
                                target_text = target_text.split(terminator)[0]
                        
                        logger.info(f"  ğŸ“ Mass info excerpt: {target_text[:200].replace(chr(10), ' ')}")
                        
                        result = parse_mass_times_from_text(target_text)
                        if result:
                            result["search_term"] = church_name
                            return result
                        else:
                            logger.warning(f"  âš ï¸ Parsing failed. Text was: {target_text[:100]}")
                else:
                    logger.warning("  âš ï¸ 'ë¯¸ì‚¬ì•ˆë‚´' text not found in body.")
                    # print(f"DEBUG_BODY: {body_text[:500]}") # ë””ë²„ê¹…

                return {
                    "raw_text": body_text[:1000],
                    "search_term": church_name
                }

            else:
                logger.warning(f"  âš ï¸ Link for '{target_name}' not found.")
                return None
                
        except Exception as e:
            logger.error(f"  âŒ Incheon handler error: {e}")
            return None

    async def handle_busan(self, page: Page, church_name: str, post: dict) -> Optional[Dict]:
        """ë¶€ì‚°êµêµ¬ í•¸ë“¤ëŸ¬ (AJAX íƒ­ ë°©ì‹ - DOM êµ¬ì¡° ê¸°ë°˜)"""
        url = DIOCESE_CONFIG["ë¶€ì‚°êµêµ¬"] # http://www.catholicbusan.or.kr/index.php?mid=page_ezLI10
        
        try:
            logger.info(f"  ğŸŒ Opening Busan diocese page...")
            await page.goto(url, timeout=20000)
            await page.wait_for_load_state("domcontentloaded")
            
            # 1. ê°€ë‚˜ë‹¤ìˆœ íƒ­ í´ë¦­
            ganada_tab = page.locator("#ganadaTab")
            if await ganada_tab.count() > 0:
                logger.info("  Clicking '#ganadaTab'...")
                await ganada_tab.click()
                await asyncio.sleep(0.5)
            else:
                logger.error("  âŒ '#ganadaTab' not found.")
                return None
            
            # 2. ì´ˆì„± íƒ­ í´ë¦­
            target_name = church_name.replace("ì„±ë‹¹", "").strip()
            chosung = get_chosung(target_name) # 'ã„±', 'ã„´', ...
            
            # ë¶€ì‚°êµêµ¬ ë§¤í•‘ (14ê°œ)
            mapping = {
                'ã„±': 0, 'ã„²': 0,
                'ã„´': 1,
                'ã„·': 2, 'ã„¸': 2,
                'ã„¹': 3,
                'ã…': 4,
                'ã…‚': 5, 'ã…ƒ': 5,
                'ã……': 6, 'ã…†': 6,
                'ã…‡': 7,
                'ã…ˆ': 8, 'ã…‰': 8,
                'ã…Š': 9,
                'ã…‹': 10,
                'ã…Œ': 11,
                'ã…': 12,
                'ã…': 13
            }
            
            idx = mapping.get(chosung)
            logger.info(f"  Church={target_name}, Chosung={chosung}, Index={idx}")
            
            if idx is None:
                logger.warning(f"  âš ï¸ Unknown chosung '{chosung}' for '{target_name}'")
                return None
            
            # <div class="word" value="idx">...</div>
            tab_btn = page.locator(f"#ganadaOrder .word[value='{idx}']")
            
            if await tab_btn.count() > 0:
                logger.info(f"  Clicking chosung tab '{chosung}' (value={idx})...")
                await tab_btn.click()
                # íƒ­ í´ë¦­ í›„ ë¦¬ìŠ¤íŠ¸ ë¡œë”© ëŒ€ê¸° 
                # (wait_for_selectorê°€ ì•Œì•„ì„œ ê¸°ë‹¤ë¦¬ê² ì§€ë§Œ í˜¹ì‹œ ëª¨ë¥´ë‹ˆ)
                await asyncio.sleep(0.5)
            else:
                logger.warning(f"  âš ï¸ Chosung tab element not found for value='{idx}'")
                return None # íƒ­ ëª» ëˆ„ë¥´ë©´ ì§„í–‰ ë¶ˆê°€

            # 3. ì„±ë‹¹ ëª©ë¡ ìŠ¤ìº” (wait_for_selector ì‚¬ìš©)
            logger.info(f"  ğŸ” Waiting for church '{target_name}' to appear...")
            
            # ì •í™•í•œ ì„±ë‹¹ ì´ë¦„ì„ ê°€ì§„ ìš”ì†Œê°€ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
            selector = f"#catholicChurch .bondang:has-text('{target_name}')"
            logger.info(f"  Waiting for selector: {selector}")
            
            try:
                # 5ì´ˆê°„ ëŒ€ê¸°
                target_el = await page.wait_for_selector(selector, state="visible", timeout=5000)
                
                if target_el:
                    logger.info("  âœ… Found church element -> Clicking...")
                    await target_el.click()
                    
                    # 4. ë¯¸ì‚¬ ì •ë³´ ë¡œë”© ëŒ€ê¸°
                    await asyncio.sleep(1.5)
                    
                    misa_content = page.locator("#misaContent")
                    if await misa_content.count() > 0:
                        content = await misa_content.inner_text()
                        logger.debug(f"  Misa Content Len={len(content)}")
                        logger.debug(f"  Misa Content Start={content[:50]}")
                        
                        logger.info(f"  ğŸ“ Content excerpt: {content[:200].replace(chr(10), ' ')}")
                        
                        result = parse_mass_times_from_text(content)
                        if result:
                            result["search_term"] = church_name
                            return result
                        else:
                            logger.warning(f"  âš ï¸ Parsing failed. Text was: {content[:100]}")
                    else:
                        logger.warning("  âš ï¸ '#misaContent' is not visible or empty.")
                else:
                    logger.warning(f"  âš ï¸ Church '{target_name}' not found (wait returned None).")
            
            except Exception as wait_err:
                logger.warning(f"  âš ï¸ Timeout waiting for '{target_name}': {wait_err}")
                
                # ë””ë²„ê¹…: í˜„ì¬ ìˆëŠ” ëª¨ë“  ë³¸ë‹¹ ì¶œë ¥
                els = await page.locator("#catholicChurch .bondang").all()
                names = [await el.inner_text() for el in els]
                logger.debug(f"  Current list: {names[:10]}...")
                
        except Exception as e:
            logger.error(f"  âŒ Busan handler error: {e}")
            
        return None

# =============================================================================
# MAIN
# =============================================================================

async def main():
    parser = argparse.ArgumentParser(description="Holy-Repair Crawler")
    parser.add_argument("--test", type=str, help="í…ŒìŠ¤íŠ¸í•  ì„±ë‹¹ëª… (ë‹¨ì¼ í…ŒìŠ¤íŠ¸)")
    parser.add_argument("--diocese", type=str, default="ì„œìš¸ëŒ€êµêµ¬", help="í…ŒìŠ¤íŠ¸í•  êµêµ¬ëª…")
    parser.add_argument("--limit", type=int, help="ì²˜ë¦¬í•  ì„±ë‹¹ ìˆ˜ ì œí•œ")
    parser.add_argument("--headless", action="store_true", help="í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ (ë¸Œë¼ìš°ì € ìˆ¨ê¹€)")
    args = parser.parse_args()

    crawler = RepairCrawler(headless=args.headless)
    await crawler.start()
    
    try:
        if args.test:
            # ë‹¨ì¼ ì„±ë‹¹ í…ŒìŠ¤íŠ¸ ëª¨ë“œ
            logger.info(f"ğŸ§ª TEST MODE: {args.test} ({args.diocese})")
            handler = crawler.get_handler(args.diocese)
            
            if handler:
                page = await crawler.context.new_page()
                mock_post = {"church_name": args.test, "diocese": args.diocese}
                
                try:
                    result = await handler(page, args.test, mock_post)
                    print("\n" + "="*50)
                    print("ğŸ“‹ RESULT:")
                    print("="*50)
                    print(json.dumps(result, ensure_ascii=False, indent=2))
                    print("="*50 + "\n")
                except Exception as e:
                    logger.error(f"ğŸ§ª Test failed: {e}")
                finally:
                    await asyncio.sleep(3)  # ê²°ê³¼ í™•ì¸ìš© ëŒ€ê¸°
            else:
                logger.error(f"âŒ No handler for: {args.diocese}")
        else:
            # ì „ì²´ íŒŒì¼ ì²˜ë¦¬ ëª¨ë“œ
            await crawler.process_files(limit=args.limit)
            
    finally:
        await crawler.stop()

if __name__ == "__main__":
    asyncio.run(main())
